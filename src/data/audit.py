"""
–ê—É–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –∏ EDA
"""

import json
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime

import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from .common import get_project_root, load_config, ensure_dir, format_number
from .ingest import load_bronze_data


def run_audit(
    df: Optional[pd.DataFrame] = None,
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞—É–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞—É–¥–∏—Ç–∞
    """
    if config is None:
        config = load_config()

    if df is None:
        df = load_bronze_data(config)

    print("="*60)
    print("–ê–£–î–ò–¢ –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–•")
    print("="*60)

    audit_results = {
        "timestamp": datetime.now().isoformat(),
        "basic_stats": {},
        "missing_values": {},
        "infinities": {},
        "duplicates": {},
        "data_types": {},
        "target_distribution": {},
        "issues": []
    }

    # 1. –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    audit_results["basic_stats"] = {
        "total_rows": len(df),
        "total_columns": len(df.columns),
        "memory_mb": round(df.memory_usage(deep=True).sum() / (1024*1024), 2)
    }
    print(f"   –°—Ç—Ä–æ–∫: {format_number(len(df))}")
    print(f"   –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
    print(f"   –ü–∞–º—è—Ç—å: {audit_results['basic_stats']['memory_mb']:.1f} MB")

    # 2. –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
    dtype_counts = df.dtypes.astype(str).value_counts().to_dict()
    audit_results["data_types"] = dtype_counts
    for dtype, count in dtype_counts.items():
        print(f"   {dtype}: {count}")

    # 3. –ü—Ä–æ–ø—É—Å–∫–∏ (NaN)
    print("\nüìä –ü—Ä–æ–ø—É—Å–∫–∏ (NaN):")
    nan_counts = df.isna().sum()
    nan_cols = nan_counts[nan_counts > 0].sort_values(ascending=False)

    audit_results["missing_values"]["total_cells_with_nan"] = int(nan_counts.sum())
    audit_results["missing_values"]["columns_with_nan"] = len(nan_cols)
    audit_results["missing_values"]["details"] = {
        col: {"count": int(count), "percent": round(100*count/len(df), 4)}
        for col, count in nan_cols.items()
    }

    if len(nan_cols) > 0:
        print(f"   –ö–æ–ª–æ–Ω–æ–∫ —Å NaN: {len(nan_cols)}")
        for col, count in nan_cols.head(10).items():
            pct = 100 * count / len(df)
            print(f"   - {col}: {format_number(count)} ({pct:.2f}%)")
        audit_results["issues"].append(f"Found {len(nan_cols)} columns with NaN values")
    else:
        print("   ‚úÖ –ü—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ—Ç")

    # 4. –ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏
    print("\nüìä –ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ (Inf):")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    inf_counts = {}

    for col in numeric_cols:
        pos_inf = (df[col] == np.inf).sum()
        neg_inf = (df[col] == -np.inf).sum()
        total_inf = pos_inf + neg_inf
        if total_inf > 0:
            inf_counts[col] = {
                "positive_inf": int(pos_inf),
                "negative_inf": int(neg_inf),
                "total": int(total_inf),
                "percent": round(100*total_inf/len(df), 4)
            }

    audit_results["infinities"]["columns_with_inf"] = len(inf_counts)
    audit_results["infinities"]["details"] = inf_counts

    if inf_counts:
        print(f"   –ö–æ–ª–æ–Ω–æ–∫ —Å Inf: {len(inf_counts)}")
        for col, info in inf_counts.items():
            print(f"   - {col}: {format_number(info['total'])} ({info['percent']:.2f}%)")
        audit_results["issues"].append(f"Found {len(inf_counts)} columns with Inf values")
    else:
        print("   ‚úÖ –ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π –Ω–µ—Ç")

    # 5. –î—É–±–ª–∏–∫–∞—Ç—ã
    print("\nüìä –î—É–±–ª–∏–∫–∞—Ç—ã:")
    full_dups = df.duplicated().sum()
    audit_results["duplicates"]["full_duplicates"] = {
        "count": int(full_dups),
        "percent": round(100*full_dups/len(df), 2)
    }
    print(f"   –ü–æ–ª–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {format_number(full_dups)} ({100*full_dups/len(df):.2f}%)")

    analysis_cols = [c for c in df.columns if not c.startswith('_')]
    dups_no_meta = df.duplicated(subset=analysis_cols).sum()
    audit_results["duplicates"]["without_meta"] = {
        "count": int(dups_no_meta),
        "percent": round(100*dups_no_meta/len(df), 2)
    }
    print(f"   –ë–µ–∑ –º–µ—Ç–∞-–∫–æ–ª–æ–Ω–æ–∫: {format_number(dups_no_meta)} ({100*dups_no_meta/len(df):.2f}%)")

    if full_dups > 0:
        audit_results["issues"].append(f"Found {full_dups:,} duplicate rows ({100*full_dups/len(df):.1f}%)")

    # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    target_col = config["ingestion"]["target_column"]
    if target_col in df.columns:
        print(f"\nüìä –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è ({target_col}):")
        target_counts = df[target_col].value_counts()
        audit_results["target_distribution"] = {
            label: {"count": int(count), "percent": round(100*count/len(df), 2)}
            for label, count in target_counts.items()
        }

        for label, count in target_counts.items():
            pct = 100 * count / len(df)
            print(f"   {label}: {format_number(count)} ({pct:.2f}%)")

    # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∫–æ–ª–æ–Ω–æ–∫
    print("\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫:")
    col_names = df.columns.tolist()
    duplicate_cols = [col for col in set(col_names) if col_names.count(col) > 1]

    if duplicate_cols:
        print(f"   ‚ö†Ô∏è –î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫: {duplicate_cols}")
        audit_results["issues"].append(f"Duplicate column names: {duplicate_cols}")
    else:
        fwd_header_cols = [c for c in col_names if 'Fwd Header Length' in c]
        if len(fwd_header_cols) > 1:
            print(f"   ‚ö†Ô∏è –ü–æ—Ö–æ–∂–∏–µ –∫–æ–ª–æ–Ω–∫–∏: {fwd_header_cols}")
            audit_results["issues"].append(f"Similar column names found: {fwd_header_cols}")
        else:
            print("   ‚úÖ –ö–æ–ª–æ–Ω–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã")

    # 8. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    print("\nüìä –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    extreme_cols = []
    for col in list(numeric_cols)[:20]:
        valid_data = df[col].replace([np.inf, -np.inf], np.nan).dropna()
        if len(valid_data) > 0:
            q1, q99 = valid_data.quantile([0.01, 0.99])
            min_val, max_val = valid_data.min(), valid_data.max()
            if max_val > q99 * 100 or (q1 != 0 and min_val < q1 * 100):
                extreme_cols.append(col)

    if extreme_cols:
        print(f"   –ö–æ–ª–æ–Ω–æ–∫ —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–º–∏ –≤—ã–±—Ä–æ—Å–∞–º–∏: {len(extreme_cols)}")
        audit_results["issues"].append(f"Columns with extreme outliers: {extreme_cols[:5]}...")

    print("\n" + "="*60)
    print(f"–ò–¢–û–ì–û –ü–†–û–ë–õ–ï–ú: {len(audit_results['issues'])}")
    for issue in audit_results["issues"]:
        print(f"   ‚ö†Ô∏è {issue}")
    print("="*60)

    return audit_results


def run_eda(
    df: Optional[pd.DataFrame] = None,
    config: Optional[Dict[str, Any]] = None,
    output_path: Optional[Path] = None,
    save_format: str = "png"  # "png" –∏–ª–∏ "html"
) -> Dict[str, Path]:
    """
    –ü—Ä–æ–≤–µ—Å—Ç–∏ EDA —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏

    Args:
        df: DataFrame
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        save_format: –§–æ—Ä–º–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ("png" –∏–ª–∏ "html")

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –ø—É—Ç—è–º–∏ –∫ —Å–æ–∑–¥–∞–Ω–Ω—ã–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º
    """
    if config is None:
        config = load_config()

    if df is None:
        df = load_bronze_data(config)

    root = get_project_root()
    if output_path is None:
        output_path = root / config["paths"]["reports"]

    ensure_dir(output_path)
    ensure_dir(output_path / "figures")

    created_files = {}
    eda_config = config.get("eda", {})
    sample_size = eda_config.get("sample_size", 100000)

    # –°—ç–º–ø–ª–∏—Ä—É–µ–º –¥–ª—è —Ç—è–∂—ë–ª—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
    if len(df) > sample_size:
        df_sample = df.sample(n=sample_size, random_state=42)
        print(f"üìä Using sample of {sample_size:,} rows for visualizations")
    else:
        df_sample = df

    target_col = config["ingestion"]["target_column"]

    def save_figure(fig: go.Figure, name: str) -> Path:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∏–≥—É—Ä—É –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        if save_format == "png":
            path = output_path / "figures" / f"{name}.png"
            fig.write_image(str(path), width=1200, height=800, scale=2)
        else:
            path = output_path / "figures" / f"{name}.html"
            fig.write_html(str(path))
        return path

    # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
    print("\nüìà Creating: Class Distribution...")
    fig = create_class_distribution_plot(df, target_col)
    path = save_figure(fig, "01_class_distribution")
    created_files["class_distribution"] = path

    # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–Ω—è–º
    if "_day" in df.columns:
        print("üìà Creating: Distribution by Day...")
        fig = create_day_distribution_plot(df, target_col)
        path = save_figure(fig, "02_day_distribution")
        created_files["day_distribution"] = path

    # 3. –î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ (log scale)
    print("üìà Creating: Class Imbalance...")
    fig = create_class_imbalance_plot(df, target_col)
    path = save_figure(fig, "03_class_imbalance_log")
    created_files["class_imbalance"] = path

    # 4. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    print("üìà Creating: Correlation Matrix...")
    fig = create_correlation_matrix(df_sample, config)
    path = save_figure(fig, "04_correlation_matrix")
    created_files["correlation_matrix"] = path

    # 5. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("üìà Creating: Feature Distributions...")
    fig = create_feature_distributions(df_sample, config)
    path = save_figure(fig, "05_feature_distributions")
    created_files["feature_distributions"] = path

    # 6. Boxplots –¥–ª—è –≤—ã–±—Ä–æ—Å–æ–≤
    print("üìà Creating: Outlier Analysis...")
    fig = create_outlier_boxplots(df_sample, config)
    path = save_figure(fig, "06_outlier_boxplots")
    created_files["outlier_boxplots"] = path

    # 7. –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
    print("üìà Creating: Features by Class...")
    fig = create_features_by_class(df_sample, target_col, config)
    path = save_figure(fig, "07_features_by_class")
    created_files["features_by_class"] = path

    # 8. –¢–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    print("üìà Creating: Top Features Analysis...")
    fig = create_top_features_analysis(df_sample, target_col)
    path = save_figure(fig, "08_top_features_binary")
    created_files["top_features"] = path

    print(f"\n‚úÖ Created {len(created_files)} visualizations in {output_path / 'figures'}")

    return created_files


def create_class_distribution_plot(df: pd.DataFrame, target_col: str) -> go.Figure:
    """–°–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤"""
    class_counts = df[target_col].value_counts().reset_index()
    class_counts.columns = ['Class', 'Count']
    class_counts['Percentage'] = (class_counts['Count'] / len(df) * 100).round(2)

    fig = make_subplots(
        rows=1, cols=2,
        specs=[[{"type": "bar"}, {"type": "pie"}]],
        subplot_titles=("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ –∫–ª–∞—Å—Å–∞–º", "–î–æ–ª—è –∫–ª–∞—Å—Å–æ–≤"),
        horizontal_spacing=0.15
    )

    colors = ['#2ecc71' if c == 'BENIGN' else '#e74c3c' for c in class_counts['Class']]

    fig.add_trace(
        go.Bar(
            x=class_counts['Class'],
            y=class_counts['Count'],
            text=[f'{c:,}' for c in class_counts['Count']],
            textposition='outside',
            marker_color=colors
        ),
        row=1, col=1
    )

    fig.add_trace(
        go.Pie(
            labels=class_counts['Class'],
            values=class_counts['Count'],
            textinfo='percent',
            hovertemplate='%{label}: %{value:,}<extra></extra>',
            hole=0.4,
            marker=dict(colors=['#2ecc71' if c == 'BENIGN' else '#e74c3c'
                               for c in class_counts['Class']])
        ),
        row=1, col=2
    )

    fig.update_layout(
        title_text="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ CIC-IDS-2017",
        title_x=0.5,
        height=500,
        showlegend=False,
        font=dict(size=12)
    )

    fig.update_xaxes(tickangle=45, row=1, col=1)

    return fig


def create_class_imbalance_plot(df: pd.DataFrame, target_col: str) -> go.Figure:
    """–°–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤ (log scale)"""
    class_counts = df[target_col].value_counts().sort_values(ascending=True)

    fig = go.Figure()

    colors = ['#2ecc71' if c == 'BENIGN' else '#e74c3c' for c in class_counts.index]

    fig.add_trace(go.Bar(
        y=class_counts.index,
        x=class_counts.values,
        orientation='h',
        text=[f'{c:,}' for c in class_counts.values],
        textposition='outside',
        marker_color=colors
    ))

    fig.update_layout(
        title='–î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞)',
        title_x=0.5,
        xaxis_title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π (log scale)',
        yaxis_title='–ö–ª–∞—Å—Å',
        xaxis_type='log',
        height=600,
        margin=dict(l=200)
    )

    return fig


def create_day_distribution_plot(df: pd.DataFrame, target_col: str) -> go.Figure:
    """–°–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –¥–Ω—è–º"""
    day_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday"]

    day_class = df.groupby(['_day', target_col]).size().reset_index(name='count')

    # –ë–∏–Ω–∞—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è
    day_class['is_attack'] = day_class[target_col].apply(lambda x: 'Attack' if x != 'BENIGN' else 'Benign')
    day_binary = day_class.groupby(['_day', 'is_attack'])['count'].sum().reset_index()

    fig = px.bar(
        day_binary,
        x='_day',
        y='count',
        color='is_attack',
        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Benign/Attack –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏',
        category_orders={'_day': day_order},
        barmode='group',
        color_discrete_map={'Benign': '#2ecc71', 'Attack': '#e74c3c'}
    )

    fig.update_layout(
        height=500,
        xaxis_title='–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏',
        yaxis_title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π',
        legend_title='–¢–∏–ø —Ç—Ä–∞—Ñ–∏–∫–∞'
    )

    return fig


def create_correlation_matrix(df: pd.DataFrame, config: Dict[str, Any]) -> go.Figure:
    """–°–æ–∑–¥–∞—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if not c.startswith('_')]

    max_features = config.get("eda", {}).get("max_features_corr", 30)
    if len(numeric_cols) > max_features:
        variances = df[numeric_cols].var().sort_values(ascending=False)
        numeric_cols = variances.head(max_features).index.tolist()

    df_clean = df[numeric_cols].replace([np.inf, -np.inf], np.nan)
    corr_matrix = df_clean.corr()

    fig = go.Figure(data=go.Heatmap(
        z=corr_matrix.values,
        x=corr_matrix.columns,
        y=corr_matrix.columns,
        colorscale='RdBu',
        zmid=0,
        hoverongaps=False,
        colorbar=dict(title='–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è')
    ))

    fig.update_layout(
        title='–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (—Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏)',
        title_x=0.5,
        height=900,
        width=1000,
        xaxis=dict(tickangle=45)
    )

    return fig


def create_feature_distributions(df: pd.DataFrame, config: Dict[str, Any]) -> go.Figure:
    """–°–æ–∑–¥–∞—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if not c.startswith('_')]

    top_n = min(16, len(numeric_cols))
    cols_to_plot = numeric_cols[:top_n]

    n_cols = 4
    n_rows = (len(cols_to_plot) + n_cols - 1) // n_cols

    fig = make_subplots(
        rows=n_rows,
        cols=n_cols,
        subplot_titles=cols_to_plot
    )

    for i, col in enumerate(cols_to_plot):
        row = i // n_cols + 1
        col_idx = i % n_cols + 1

        valid_data = df[col].replace([np.inf, -np.inf], np.nan).dropna()
        q01, q99 = valid_data.quantile([0.01, 0.99])
        clipped = valid_data.clip(q01, q99)

        fig.add_trace(
            go.Histogram(x=clipped, nbinsx=30, name=col, showlegend=False,
                        marker_color='#3498db'),
            row=row,
            col=col_idx
        )

    fig.update_layout(
        title_text="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (1-99 percentile)",
        title_x=0.5,
        height=200 * n_rows,
        showlegend=False
    )

    return fig


def create_outlier_boxplots(df: pd.DataFrame, config: Dict[str, Any]) -> go.Figure:
    """–°–æ–∑–¥–∞—Ç—å boxplots –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—ã–±—Ä–æ—Å–æ–≤"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if not c.startswith('_')]

    top_n = min(12, len(numeric_cols))
    cols_to_plot = numeric_cols[:top_n]

    fig = go.Figure()

    for col in cols_to_plot:
        valid_data = df[col].replace([np.inf, -np.inf], np.nan).dropna()

        if valid_data.std() > 0:
            normalized = (valid_data - valid_data.mean()) / valid_data.std()
        else:
            normalized = valid_data

        fig.add_trace(go.Box(y=normalized.sample(min(10000, len(normalized))),
                             name=col, showlegend=False))

    fig.update_layout(
        title_text="–ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤ (Z-score –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)",
        title_x=0.5,
        height=500,
        showlegend=False,
        yaxis_title='Z-score'
    )

    return fig


def create_features_by_class(
    df: pd.DataFrame,
    target_col: str,
    config: Dict[str, Any]
) -> go.Figure:
    """–°–æ–∑–¥–∞—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if not c.startswith('_')]

    cols_to_plot = numeric_cols[:6]

    fig = make_subplots(
        rows=2,
        cols=3,
        subplot_titles=cols_to_plot
    )

    df_plot = df.copy()
    df_plot['_binary_class'] = df_plot[target_col].apply(
        lambda x: 'BENIGN' if x == 'BENIGN' else 'ATTACK'
    )

    for i, col in enumerate(cols_to_plot):
        row = i // 3 + 1
        col_idx = i % 3 + 1

        for class_name, color in [('BENIGN', '#2ecc71'), ('ATTACK', '#e74c3c')]:
            class_data = df_plot[df_plot['_binary_class'] == class_name][col]
            class_data = class_data.replace([np.inf, -np.inf], np.nan).dropna()

            if len(class_data) > 10000:
                class_data = class_data.sample(10000)

            q01, q99 = class_data.quantile([0.01, 0.99])
            clipped = class_data.clip(q01, q99)

            fig.add_trace(
                go.Histogram(
                    x=clipped,
                    name=class_name,
                    opacity=0.7,
                    marker_color=color,
                    showlegend=(i == 0),
                    nbinsx=30
                ),
                row=row,
                col=col_idx
            )

    fig.update_layout(
        title_text="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: BENIGN vs ATTACK",
        title_x=0.5,
        height=600,
        barmode='overlay'
    )

    return fig


def create_top_features_analysis(df: pd.DataFrame, target_col: str) -> go.Figure:
    """–ê–Ω–∞–ª–∏–∑ —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if not c.startswith('_')]

    df_sample = df.sample(min(50000, len(df)), random_state=42).copy()
    df_sample['is_attack'] = (df_sample[target_col] != 'BENIGN').astype(int)

    # –°—á–∏—Ç–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É —Å—Ä–µ–¥–Ω–∏—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
    feature_importance = {}
    for col in numeric_cols:
        valid_data = df_sample[col].replace([np.inf, -np.inf], np.nan)
        if valid_data.isna().sum() < len(valid_data) * 0.5:
            benign_mean = valid_data[df_sample['is_attack'] == 0].mean()
            attack_mean = valid_data[df_sample['is_attack'] == 1].mean()
            if pd.notna(benign_mean) and pd.notna(attack_mean):
                # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞
                diff = abs(attack_mean - benign_mean) / (abs(benign_mean) + 1e-10)
                feature_importance[col] = diff

    # –¢–æ–ø-15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:15]

    fig = go.Figure()

    fig.add_trace(go.Bar(
        y=[f[0] for f in top_features],
        x=[f[1] for f in top_features],
        orientation='h',
        marker_color='#3498db'
    ))

    fig.update_layout(
        title='–¢–æ–ø-15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ —Ä–∞–∑–ª–∏—á–∏—é BENIGN vs ATTACK',
        title_x=0.5,
        xaxis_title='–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ —Å—Ä–µ–¥–Ω–∏—Ö',
        yaxis_title='–ü—Ä–∏–∑–Ω–∞–∫',
        height=600,
        margin=dict(l=250)
    )

    return fig


def generate_report(
    audit_results: Dict[str, Any],
    eda_files: Dict[str, Path],
    config: Optional[Dict[str, Any]] = None,
    output_path: Optional[Path] = None
) -> Path:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á—ë—Ç"""
    if config is None:
        config = load_config()

    root = get_project_root()
    if output_path is None:
        output_path = root / config["paths"]["reports"]

    ensure_dir(output_path)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    first_file = list(eda_files.values())[0] if eda_files else None
    img_ext = first_file.suffix if first_file else ".png"

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    img_tags = ""
    for name, path in eda_files.items():
        if img_ext == ".png":
            img_tags += f'''
            <div class="viz-container">
                <h3>{name.replace("_", " ").title()}</h3>
                <img src="figures/{path.name}" alt="{name}" style="max-width:100%; height:auto;">
            </div>
            '''
        else:
            img_tags += f'''
            <div class="viz-container">
                <h3>{name.replace("_", " ").title()}</h3>
                <iframe src="figures/{path.name}" width="100%" height="600px" frameborder="0"></iframe>
            </div>
            '''

    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>CIC-IDS-2017 Data Audit Report</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 0; padding: 20px; background: #f0f2f5; }}
            .container {{ max-width: 1400px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            h1 {{ color: #1a73e8; border-bottom: 3px solid #1a73e8; padding-bottom: 15px; }}
            h2 {{ color: #202124; margin-top: 40px; padding-bottom: 10px; border-bottom: 1px solid #dadce0; }}
            h3 {{ color: #5f6368; }}
            .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }}
            .stat-card {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 25px; border-radius: 12px; text-align: center; color: white; }}
            .stat-value {{ font-size: 36px; font-weight: bold; }}
            .stat-label {{ opacity: 0.9; margin-top: 5px; font-size: 14px; }}
            table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
            th, td {{ padding: 12px 15px; text-align: left; border-bottom: 1px solid #e0e0e0; }}
            th {{ background: #f8f9fa; font-weight: 600; color: #202124; }}
            tr:hover {{ background: #f8f9fa; }}
            .issue {{ background: #fef7e0; padding: 12px 16px; margin: 8px 0; border-left: 4px solid #f9ab00; border-radius: 4px; }}
            .success {{ background: #e6f4ea; padding: 12px 16px; margin: 8px 0; border-left: 4px solid #34a853; border-radius: 4px; }}
            .viz-container {{ margin: 30px 0; padding: 20px; background: #fafafa; border-radius: 8px; }}
            .viz-container img {{ border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}
            .summary-box {{ background: #e8f0fe; padding: 20px; border-radius: 8px; margin: 20px 0; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üìä CIC-IDS-2017 Data Audit Report</h1>
            <p><strong>Generated:</strong> {audit_results['timestamp']}</p>
            
            <h2>üìà –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-value">{format_number(audit_results['basic_stats']['total_rows'])}</div>
                    <div class="stat-label">–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{audit_results['basic_stats']['total_columns']}</div>
                    <div class="stat-label">–ö–æ–ª–æ–Ω–æ–∫</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{audit_results['basic_stats']['memory_mb']} MB</div>
                    <div class="stat-label">–†–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏</div>
                </div>
                <div class="stat-card" style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);">
                    <div class="stat-value">{len(audit_results['issues'])}</div>
                    <div class="stat-label">–ü—Ä–æ–±–ª–µ–º –Ω–∞–π–¥–µ–Ω–æ</div>
                </div>
            </div>
            
            <h2>üéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤</h2>
            <table>
                <tr><th>–ö–ª–∞—Å—Å</th><th>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ</th><th>–î–æ–ª—è</th></tr>
                {"".join(f"<tr><td>{'üü¢ ' if label == 'BENIGN' else 'üî¥ '}{label}</td><td>{format_number(info['count'])}</td><td>{info['percent']:.2f}%</td></tr>" for label, info in audit_results['target_distribution'].items())}
            </table>
            
            <div class="summary-box">
                <strong>üìå –†–µ–∑—é–º–µ –ø–æ –∫–ª–∞—Å—Å–∞–º:</strong>
                <ul>
                    <li>BENIGN (–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç—Ä–∞—Ñ–∏–∫): {audit_results['target_distribution'].get('BENIGN', {}).get('percent', 0):.1f}%</li>
                    <li>–ê—Ç–∞–∫–∏: {100 - audit_results['target_distribution'].get('BENIGN', {}).get('percent', 0):.1f}%</li>
                    <li>–†–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã (<100 –∑–∞–ø–∏—Å–µ–π): Heartbleed, Infiltration, SQL Injection</li>
                </ul>
            </div>
            
            <h2>‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã</h2>
            {"".join(f'<div class="issue">‚ö†Ô∏è {issue}</div>' for issue in audit_results['issues']) if audit_results['issues'] else '<div class="success">‚úÖ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!</div>'}
            
            <h2>üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏</h2>
            {img_tags}
            
            <h2>üìã –î–µ—Ç–∞–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö</h2>
            <h3>–ü—Ä–æ–ø—É—Å–∫–∏ (NaN)</h3>
            <p>–ö–æ–ª–æ–Ω–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: <strong>{audit_results['missing_values'].get('columns_with_nan', 0)}</strong></p>
            
            <h3>–ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ (Inf)</h3>
            <p>–ö–æ–ª–æ–Ω–æ–∫ —Å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—è–º–∏: <strong>{audit_results['infinities'].get('columns_with_inf', 0)}</strong></p>
            
            <h3>–î—É–±–ª–∏–∫–∞—Ç—ã</h3>
            <p>–ü–æ–ª–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: <strong>{format_number(audit_results['duplicates']['full_duplicates']['count'])}</strong> ({audit_results['duplicates']['full_duplicates']['percent']}%)</p>
        </div>
    </body>
    </html>
    """

    report_path = output_path / "data_audit_report.html"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(html_content)

    # JSON –æ—Ç—á—ë—Ç
    json_path = output_path / "audit_results.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(audit_results, f, indent=2, ensure_ascii=False, default=str)

    print(f"\n‚úÖ Report saved to: {report_path}")

    return report_path